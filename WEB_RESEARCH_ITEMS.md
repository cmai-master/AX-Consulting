# ì›¹ ë¦¬ì„œì¹˜ í•­ëª© ëª©ë¡

> **ëª©ì **: ì»¨ì„¤íŒ… ìì‚° 110ê°œ ë¬¸ì„œ ì‘ì„±ì„ ìœ„í•œ ì›¹ ê¸°ë°˜ ì •ë³´ ìˆ˜ì§‘ ê³„íš
> **ì‘ì„±ì¼**: 2025-11-23
> **ì´ ë¦¬ì„œì¹˜ í•­ëª©**: 80ê°œ (High: 35ê°œ, Medium: 30ê°œ, Low: 15ê°œ)

---

## ğŸ“‹ ëª©ì°¨

1. [ìš°ì„ ìˆœìœ„ ê°œìš”](#ìš°ì„ ìˆœìœ„-ê°œìš”)
2. [High Priority - ì¦‰ì‹œ ë¦¬ì„œì¹˜](#high-priority---ì¦‰ì‹œ-ë¦¬ì„œì¹˜)
3. [Medium Priority - 2ì°¨ ë¦¬ì„œì¹˜](#medium-priority---2ì°¨-ë¦¬ì„œì¹˜)
4. [Low Priority - ì¶”ê°€ ë¦¬ì„œì¹˜](#low-priority---ì¶”ê°€-ë¦¬ì„œì¹˜)
5. [ë¦¬ì„œì¹˜ ë°©ë²•ë¡ ](#ë¦¬ì„œì¹˜-ë°©ë²•ë¡ )

---

## ìš°ì„ ìˆœìœ„ ê°œìš”

| Priority | í•­ëª© ìˆ˜ | ì˜ˆìƒ ì†Œìš” | ëª©ì  |
|----------|---------|-----------|------|
| **High** | 35ê°œ | 40-60ì‹œê°„ | í•µì‹¬ ë°©ë²•ë¡  ë° ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± ê¸°ë°˜ |
| **Medium** | 30ê°œ | 30-40ì‹œê°„ | í…œí”Œë¦¿ ë° ê°€ì´ë“œ ì‘ì„± ê¸°ë°˜ |
| **Low** | 15ê°œ | 20-30ì‹œê°„ | ì°¸ê³  ìë£Œ ë° ë³´ì™„ ì •ë³´ |
| **Total** | **80ê°œ** | **90-130ì‹œê°„** | |

---

## HIGH PRIORITY - ì¦‰ì‹œ ë¦¬ì„œì¹˜

### ğŸ¯ 1. RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ

#### 1.1 RAG ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ íŒ¨í„´
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - RAG ì‹œìŠ¤í…œ ì „ì²´ ì•„í‚¤í…ì²˜ (Naive RAG, Advanced RAG, Modular RAG)
  - êµ¬ì„± ìš”ì†Œë³„ ì„¤ê³„ íŒ¨í„´
  - End-to-end íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic ê³µì‹ ë¬¸ì„œ ë° Cookbook
  - LangChain RAG ê°€ì´ë“œ
  - arXiv ìµœì‹  RAG ë…¼ë¬¸ (2024-2025)
  - Pinecone, Weaviate ê¸°ìˆ  ë¸”ë¡œê·¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-1: RAG System Design Methodology
  - C2-2: RAG System Implementation Guide
  - B3-3: Context Model Canvas

- **ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„
- **ì‚°ì¶œë¬¼**: RAG ì•„í‚¤í…ì²˜ íŒ¨í„´ ê°€ì´ë“œ, ì„¤ê³„ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

#### 1.2 Chunking ì „ëµ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Fixed-size chunking
  - Semantic chunking
  - Recursive chunking
  - Context-aware chunking
  - ê° ì „ëµì˜ ì¥ë‹¨ì  ë° ì ìš© ì‹œë‚˜ë¦¬ì˜¤

- **ì£¼ìš” ì†ŒìŠ¤**:
  - LlamaIndex ë¬¸ì„œ
  - LangChain Text Splitters
  - Greg Kamradtì˜ Chunking ì—°êµ¬
  - Unstructured.io ë¸”ë¡œê·¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-1: RAG System Design Methodology
  - C2-2: RAG System Implementation Guide
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Chunking ì „ëµ ë¹„êµí‘œ, ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸

#### 1.3 Embedding ëª¨ë¸ ë¹„êµ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - OpenAI (text-embedding-3-small/large)
  - Cohere (embed-v3)
  - Voyage AI
  - ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ (BGE, E5, Instructor)
  - MTEB ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
  - ëª¨ë¸ë³„ íŠ¹ì„± (ì°¨ì›, ë‹¤êµ­ì–´, ë„ë©”ì¸ íŠ¹í™”)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - MTEB Leaderboard
  - ê° ì œê³µì‚¬ ê³µì‹ ë¬¸ì„œ
  - HuggingFace Model Hub

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-1: RAG System Design Methodology
  - B3-2: Technology Stack Assessment Matrix
  - D4-1: Technology Landscape

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Embedding ëª¨ë¸ ë¹„êµ ë§¤íŠ¸ë¦­ìŠ¤, ì„ ì • ê°€ì´ë“œ

#### 1.4 Vector Database ë¹„êµ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Pinecone, Weaviate, Qdrant, Milvus, ChromaDB, Faiss
  - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (QPS, latency, recall)
  - ê¸°ëŠ¥ ë¹„êµ (í•„í„°ë§, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, ìŠ¤ì¼€ì¼ë§)
  - ê°€ê²© ë¹„êµ
  - ë°°í¬ ì˜µì…˜ (í´ë¼ìš°ë“œ, ì˜¨í”„ë ˆë¯¸ìŠ¤, í•˜ì´ë¸Œë¦¬ë“œ)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê° Vector DB ê³µì‹ ë¬¸ì„œ
  - VectorDBBench
  - ë…ë¦½ì  ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B3-2: Technology Stack Assessment Matrix
  - D4-1: Technology Landscape
  - A3-1: Enterprise AI Platform Reference Architecture

- **ì˜ˆìƒ ì‹œê°„**: 5-6ì‹œê°„
- **ì‚°ì¶œë¬¼**: Vector DB ë¹„êµí‘œ, ì„ ì • ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

#### 1.5 Retrieval ì „ëµ ë° ìµœì í™”
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Similarity search (cosine, euclidean, dot product)
  - Hybrid search (keyword + semantic)
  - Re-ranking ê¸°ë²•
  - Query transformation (HyDE, Multi-query, Step-back)
  - Contextual compression
  - Maximum Marginal Relevance (MMR)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - LangChain Retrieval ê°€ì´ë“œ
  - Anthropic Contextual Retrieval
  - Cohere Re-ranking ë¬¸ì„œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-1: RAG System Design Methodology
  - C2-2: RAG System Implementation Guide
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Retrieval ì „ëµ í”Œë ˆì´ë¶, ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

#### 1.6 RAG Evaluation ë©”íŠ¸ë¦­
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Retrieval ë©”íŠ¸ë¦­ (Precision@k, Recall@k, MRR, NDCG)
  - Generation ë©”íŠ¸ë¦­ (Faithfulness, Answer Relevancy, Context Precision/Recall)
  - End-to-end ë©”íŠ¸ë¦­
  - RAGAS, TruLens, DeepEval í”„ë ˆì„ì›Œí¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - RAGAS ë¬¸ì„œ
  - TruLens ê°€ì´ë“œ
  - arXiv RAG evaluation ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A5-2: AI System Evaluation Framework
  - B4-3: Evaluation Dataset Template
  - C2-2: RAG System Implementation Guide

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: RAG í‰ê°€ ë©”íŠ¸ë¦­ ê°€ì´ë“œ, í‰ê°€ í”„ë¡œí† ì½œ

---

### ğŸ¤– 2. Agent & Multi-Agent Systems

#### 2.1 Agent ì•„í‚¤í…ì²˜ íŒ¨í„´
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ReAct (Reasoning + Acting)
  - Plan-and-Execute
  - Reflection/Self-Critique
  - Tree of Thoughts
  - Agent êµ¬ì„± ìš”ì†Œ (Memory, Tools, Planning, Execution)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic Agent ê°€ì´ë“œ
  - LangChain Agents
  - arXiv Agent ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A1-3: Agent Orchestration Framework
  - B3-4: Agent Design Canvas
  - C2-3: Agent Development Guide

- **ì˜ˆìƒ ì‹œê°„**: 5-6ì‹œê°„
- **ì‚°ì¶œë¬¼**: Agent íŒ¨í„´ ì¹´íƒˆë¡œê·¸, ì„¤ê³„ ê°€ì´ë“œ

#### 2.2 Multi-Agent Orchestration
- **ë¦¬ì„œÚ†  ë‚´ìš©**:
  - Multi-agent íŒ¨í„´ (Hierarchical, Sequential, Parallel, Network)
  - Communication protocols
  - Coordination strategies
  - Conflict resolution
  - LangGraph, CrewAI, AutoGen ë¹„êµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - LangGraph ë¬¸ì„œ
  - CrewAI ë¬¸ì„œ
  - Microsoft AutoGen
  - Multi-agent ì—°êµ¬ ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A1-3: Agent Orchestration Framework
  - C2-3: Agent Development Guide
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 6-7ì‹œê°„
- **ì‚°ì¶œë¬¼**: Multi-agent íŒ¨í„´ ê°€ì´ë“œ, í”„ë ˆì„ì›Œí¬ ë¹„êµí‘œ

#### 2.3 Agent Memory Architecture
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Short-term memory (conversation buffer, window)
  - Long-term memory (vector store, knowledge graph)
  - Semantic memory vs Episodic memory
  - Memory retrieval strategies
  - Memory management íŒ¨í„´

- **ì£¼ìš” ì†ŒìŠ¤**:
  - LangChain Memory
  - Mem0 (memory framework)
  - Agent memory ì—°êµ¬ ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A1-3: Agent Orchestration Framework
  - B3-4: Agent Design Canvas
  - C2-3: Agent Development Guide

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Memory ì•„í‚¤í…ì²˜ íŒ¨í„´, êµ¬í˜„ ê°€ì´ë“œ

#### 2.4 Tool Integration & Function Calling
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Function calling ë©”ì»¤ë‹ˆì¦˜
  - Tool definition ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
  - Error handling
  - Tool orchestration
  - Security considerations

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic Tool Use ê°€ì´ë“œ
  - OpenAI Function Calling
  - LangChain Tools

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B3-4: Agent Design Canvas
  - C2-3: Agent Development Guide
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Tool Integration ê°€ì´ë“œ, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

---

### ğŸ—ï¸ 3. Enterprise AI Platform & Architecture

#### 3.1 Enterprise AI Platform ì°¸ì¡° ì•„í‚¤í…ì²˜
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Layered architecture (Data, Model, Application, User)
  - í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ (Model Serving, Vector Store, Orchestration)
  - ì„ íƒ ì»´í¬ë„ŒíŠ¸ (Feature Store, Experiment Tracking)
  - Integration patterns
  - Security layer

- **ì£¼ìš” ì†ŒìŠ¤**:
  - AWS AI/ML Reference Architecture
  - Google Cloud AI Platform
  - Azure AI Platform
  - Databricks AI Platform

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-1: Enterprise AI Platform Reference Architecture
  - C1-3: Enterprise AI Platform Playbook
  - B3-2: Technology Stack Assessment Matrix

- **ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„
- **ì‚°ì¶œë¬¼**: ì°¸ì¡° ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨, ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œ

#### 3.2 Semantic Layer & Knowledge Graph
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Semantic layer ê°œë… ë° ì„¤ê³„
  - Ontology ëª¨ë¸ë§ ê¸°ë²•
  - Knowledge graph êµ¬ì¶• ë°©ë²•ë¡ 
  - Graph database (Neo4j, Amazon Neptune, TigerGraph)
  - Query ìµœì í™”

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Neo4j ë¬¸ì„œ ë° Graph Academy
  - W3C Semantic Web í‘œì¤€
  - Knowledge Graph ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A1-2: Context Engineering Methodology
  - C2-1: Context Engineering Implementation Guide
  - B3-3: Context Model Canvas

- **ì˜ˆìƒ ì‹œê°„**: 6-7ì‹œê°„
- **ì‚°ì¶œë¬¼**: Semantic Layer ì„¤ê³„ ê°€ì´ë“œ, KG ëª¨ë¸ë§ íŒ¨í„´

#### 3.3 MLOps íŒŒì´í”„ë¼ì¸ ë° ë„êµ¬
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - MLOps ë‹¨ê³„ (Data, Training, Serving, Monitoring)
  - CI/CD for ML
  - Model versioning & registry
  - Experiment tracking
  - MLflow, Kubeflow, Weights & Biases ë¹„êµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - MLOps ì»¤ë®¤ë‹ˆí‹° ê°€ì´ë“œ
  - Google MLOps Maturity Model
  - ê° ë„êµ¬ ê³µì‹ ë¬¸ì„œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-2: MLOps Reference Architecture
  - C2-4: MLOps Pipeline Setup Guide
  - D4-1: Technology Landscape

- **ì˜ˆìƒ ì‹œê°„**: 5-6ì‹œê°„
- **ì‚°ì¶œë¬¼**: MLOps íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ, ë„êµ¬ ë¹„êµí‘œ

#### 3.4 Model Serving & Deployment íŒ¨í„´
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Deployment íŒ¨í„´ (Blue-Green, Canary, A/B)
  - Scaling strategies
  - API Gateway patterns
  - Rate limiting & throttling
  - Cost optimization

- **ì£¼ìš” ì†ŒìŠ¤**:
  - AWS SageMaker
  - Kubernetes for ML
  - Model serving í”„ë ˆì„ì›Œí¬ (TorchServe, TensorFlow Serving)

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-1: Enterprise AI Platform Reference Architecture
  - C2-4: MLOps Pipeline Setup Guide
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Deployment íŒ¨í„´ ê°€ì´ë“œ, ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

---

### ğŸ“Š 4. Prompt Engineering & Optimization

#### 4.1 Prompt Engineering ê¸°ë²•
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Zero-shot, Few-shot, Many-shot
  - Chain-of-Thought (CoT)
  - Tree of Thoughts
  - ReAct prompting
  - System prompts vs User prompts
  - Prompt êµ¬ì¡° ë° í…œí”Œë¦¿

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic Prompt Engineering Guide
  - OpenAI Prompt Engineering
  - Prompt Engineering Guide (dair.ai)

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-2: Prompt Engineering Framework
  - B4-4: Prompt Library Template
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Prompt íŒ¨í„´ ì¹´íƒˆë¡œê·¸, ì‘ì„± ê°€ì´ë“œ

#### 4.2 Prompt Optimization í”„ë¡œì„¸ìŠ¤
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Prompt iteration ë°©ë²•ë¡ 
  - A/B testing for prompts
  - Prompt versioning
  - Performance ì¸¡ì •
  - DSPy, PromptPerfect ë“± ìë™í™” ë„êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - DSPy í”„ë ˆì„ì›Œí¬
  - Prompt optimization ì—°êµ¬
  - ì‹¤ë¬´ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-2: Prompt Engineering Framework
  - B4-4: Prompt Library Template
  - C2-3: Agent Development Guide

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Optimization í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ, í…œí”Œë¦¿

---

### ğŸ¯ 5. AI Maturity & Assessment

#### 5.1 AI Maturity Models
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Gartner AI Maturity Model
  - McKinsey AI Maturity
  - Forrester AI Maturity
  - 5-level maturity framework
  - í‰ê°€ ì°¨ì› (Strategy, Data, Technology, People, Process, Governance)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Gartner ë¦¬í¬íŠ¸
  - McKinsey Analytics
  - Forrester Research
  - í•™ìˆ  ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A2-1: AI Maturity Model
  - B1-1: AI Maturity Assessment Questionnaire
  - C1-1: AI Strategy & Readiness Playbook

- **ì˜ˆìƒ ì‹œê°„**: 5-6ì‹œê°„
- **ì‚°ì¶œë¬¼**: Maturity Model í”„ë ˆì„ì›Œí¬, í‰ê°€ ê¸°ì¤€

#### 5.2 Use Case Prioritization í”„ë ˆì„ì›Œí¬
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Value vs Effort ë§¤íŠ¸ë¦­ìŠ¤
  - RICE (Reach, Impact, Confidence, Effort)
  - Weighted scoring models
  - Risk-adjusted prioritization
  - AI íŠ¹í™” í‰ê°€ ê¸°ì¤€ (ë°ì´í„° ê°€ìš©ì„±, ê¸°ìˆ  ì„±ìˆ™ë„)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Product management í”„ë ˆì„ì›Œí¬
  - AI ì „ëµ ì»¨ì„¤íŒ… ë°©ë²•ë¡ 
  - McKinsey, BCG ì¼€ì´ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A2-2: Use Case Prioritization Framework
  - B2-2: Use Case Prioritization Scorecard
  - C3-2: Use Case Prioritization Guide

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Prioritization í”„ë ˆì„ì›Œí¬, ìŠ¤ì½”ì–´ì¹´ë“œ

---

### âš ï¸ 6. AI Risk & Compliance

#### 6.1 AI Risk Taxonomy
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - NIST AI Risk Management Framework
  - AI ë¦¬ìŠ¤í¬ ë¶„ë¥˜ (Technical, Operational, Ethical, Legal)
  - Likelihood Ã— Impact í‰ê°€
  - Risk mitigation strategies

- **ì£¼ìš” ì†ŒìŠ¤**:
  - NIST AI RMF
  - ISO/IEC 23894 (AI Risk Management)
  - EU AI Act

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A2-3: Risk Assessment Framework
  - B6-1: Risk Register
  - B6-2: Risk Assessment Worksheet
  - C3-3: Risk Assessment Execution Guide

- **ì˜ˆìƒ ì‹œê°„**: 5-6ì‹œê°„
- **ì‚°ì¶œë¬¼**: Risk Taxonomy, í‰ê°€ í”„ë ˆì„ì›Œí¬

#### 6.2 AI ê·œì œ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - EU AI Act (High-risk systems, prohibited practices)
  - GDPR (AI ê´€ë ¨ ì¡°í•­)
  - í•œêµ­ ê°œì¸ì •ë³´ë³´í˜¸ë²•
  - ISO/IEC 42001 (AI Management System)
  - ì‚°ì—…ë³„ ê·œì œ (ê¸ˆìœµ, ì˜ë£Œ, ê³µê³µ)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - EU ê³µì‹ ë¬¸ì„œ
  - ISO í‘œì¤€
  - ê¸ˆìœµìœ„ì›íšŒ, ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ ê°€ì´ë“œë¼ì¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B6-3: Compliance Checklist
  - C1-6: AI Risk & Compliance Playbook
  - D4-1: Technology Landscape

- **ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„
- **ì‚°ì¶œë¬¼**: ê·œì œ ìš”êµ¬ì‚¬í•­ ë§¤í•‘, ì»´í”Œë¼ì´ì–¸ìŠ¤ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### 6.3 Fairness & Bias Assessment
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Bias ìœ í˜• (Selection, Measurement, Algorithm)
  - Protected attributes
  - Fairness ë©”íŠ¸ë¦­ (Demographic Parity, Equal Opportunity, Equalized Odds)
  - Bias detection ë„êµ¬ (AI Fairness 360, Fairlearn)
  - Mitigation ê¸°ë²•

- **ì£¼ìš” ì†ŒìŠ¤**:
  - IBM AI Fairness 360
  - Microsoft Fairlearn
  - Google PAIR (People + AI Research)
  - í•™ìˆ  ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B6-5: Fairness Assessment Template
  - C1-6: AI Risk & Compliance Playbook
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Fairness í‰ê°€ ê°€ì´ë“œ, Mitigation í”Œë ˆì´ë¶

#### 6.4 Model Governance & Documentation
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Model Card í‘œì¤€ (Google)
  - Model lifecycle management
  - Stage-gate í”„ë¡œì„¸ìŠ¤
  - Approval workflow
  - Model drift detection

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Google Model Cards
  - Microsoft Responsible AI
  - MLOps ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-3: Model Governance Methodology
  - B5-5: Model Card Template
  - B5-3: Stage-gate Review Checklist

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Governance í”„ë¡œì„¸ìŠ¤, Model Card í…œí”Œë¦¿

---

### ğŸ’° 7. ROI & Business Value

#### 7.1 AI í”„ë¡œì íŠ¸ ROI ê³„ì‚° ëª¨ë¸
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Cost structure (ì¸í”„ë¼, ì¸ë ¥, ë¼ì´ì„ ìŠ¤, ë°ì´í„°)
  - Benefit ì¸¡ì • (ë¹„ìš© ì ˆê°, ë§¤ì¶œ ì¦ëŒ€, ë¦¬ìŠ¤í¬ ê°ì†Œ)
  - ROI ê³„ì‚° ê³µì‹
  - Payback period
  - NPV, IRR
  - ë¯¼ê°ë„ ë¶„ì„

- **ì£¼ìš” ì†ŒìŠ¤**:
  - McKinsey AI ROI ì—°êµ¬
  - Gartner TCO ëª¨ë¸
  - AWS, GCP ë¹„ìš© ê³„ì‚°ê¸°

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A5-1: AI Project ROI Model
  - B2-4: Investment Plan & Budget Template
  - E2-3: ROI Calculator

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: ROI ê³„ì‚° ëª¨ë¸, í…œí”Œë¦¿

#### 7.2 AI íˆ¬ì ë²¤ì¹˜ë§ˆí¬
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ì‚°ì—…ë³„ AI íˆ¬ì í˜„í™©
  - í”„ë¡œì íŠ¸ ê·œëª¨ë³„ ë¹„ìš© ë²”ìœ„
  - í‰ê·  ROI ë°ì´í„°
  - ì„±ê³µë¥  í†µê³„

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Gartner, Forrester ë¦¬í¬íŠ¸
  - McKinsey State of AI
  - ì‚°ì—… ë¦¬í¬íŠ¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A5-1: AI Project ROI Model
  - E2-2: Pricing Guide & Calculator

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°, ë¹„êµ ìë£Œ

---

### ğŸ¨ 8. LLM Platforms & Models

#### 8.1 LLM í”Œë«í¼ ë¹„êµ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Claude (Sonnet, Opus, Haiku)
  - GPT-4, GPT-4 Turbo, GPT-4o
  - Gemini (Pro, Ultra)
  - ì˜¤í”ˆì†ŒìŠ¤ (Llama, Mistral, Qwen)
  - ëª¨ë¸ë³„ íŠ¹ì„± (context window, capabilities, pricing)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic, OpenAI, Google ê³µì‹ ë¬¸ì„œ
  - Artificial Analysis ë²¤ì¹˜ë§ˆí¬
  - HuggingFace Leaderboards

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-1: Technology Landscape
  - B3-2: Technology Stack Assessment Matrix

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: LLM ë¹„êµí‘œ, ì„ ì • ê°€ì´ë“œ

#### 8.2 Context Window ìµœì í™”
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Long context handling
  - Context compression ê¸°ë²•
  - Sliding window
  - Prompt caching
  - Cost optimization

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic Prompt Caching
  - LongLLMLingua
  - Context optimization ì—°êµ¬

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D2-1: Technical Best Practices
  - A4-2: Prompt Engineering Framework

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Context ìµœì í™” ê°€ì´ë“œ

---

### ğŸ“ˆ 9. Monitoring & Observability

#### 9.1 LLM Observability í”Œë«í¼
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - LangSmith, Arize, WhyLabs, Helicone ë¹„êµ
  - Tracing & debugging
  - Performance monitoring
  - Cost tracking
  - User feedback ìˆ˜ì§‘

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê° í”Œë«í¼ ê³µì‹ ë¬¸ì„œ
  - LLMOps ê°€ì´ë“œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-2: MLOps Reference Architecture
  - D4-1: Technology Landscape

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Observability í”Œë«í¼ ë¹„êµ, êµ¬ì¶• ê°€ì´ë“œ

#### 9.2 Model Performance Monitoring
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Drift detection (data drift, concept drift)
  - Performance degradation
  - Alerting strategies
  - Retraining triggers

- **ì£¼ìš” ì†ŒìŠ¤**:
  - MLOps ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ
  - Evidently AI, NannyML

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A4-3: Model Governance Methodology
  - C2-4: MLOps Pipeline Setup Guide

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Monitoring ì „ëµ, êµ¬í˜„ ê°€ì´ë“œ

---

### ğŸ¢ 10. AI Operating Model & Organization

#### 10.1 AI CoE (Center of Excellence) ëª¨ë¸
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Centralized vs Federated vs Hybrid
  - Hub & Spoke model
  - ê° ëª¨ë¸ì˜ ì¥ë‹¨ì 
  - ì ìš© ì¡°ê±´ ë° ì „í™˜ ê²½ë¡œ
  - ì„±ê³µ ì‚¬ë¡€

- **ì£¼ìš” ì†ŒìŠ¤**:
  - McKinsey, BCG ì¡°ì§ ì„¤ê³„ ì—°êµ¬
  - Gartner AI CoE ê°€ì´ë“œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-3: Operating Model Patterns
  - C1-2: AI Operating Model Playbook

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Operating Model íŒ¨í„´ ê°€ì´ë“œ

#### 10.2 AI ê±°ë²„ë„ŒìŠ¤ êµ¬ì¡°
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Governance committee êµ¬ì¡°
  - ì˜ì‚¬ê²°ì • ê¶Œí•œ (RACI)
  - Policy framework
  - Compliance monitoring

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ISO/IEC 38500 (IT Governance)
  - AI ê±°ë²„ë„ŒìŠ¤ í”„ë ˆì„ì›Œí¬

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-3: Operating Model Patterns
  - B5-2: RACI Matrix Template
  - B5-4: Policy Document Template

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Governance êµ¬ì¡°, í…œí”Œë¦¿

---

## MEDIUM PRIORITY - 2ì°¨ ë¦¬ì„œì¹˜

### ğŸ“ 11. Templates & Standards

#### 11.1 Architecture Decision Record (ADR)
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ADR í‘œì¤€ í¬ë§· (MADR, Nygard)
  - ì‘ì„± ê°€ì´ë“œ
  - ì˜ˆì‹œ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ADR GitHub
  - adr.github.io

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B3-1: Architecture Decision Record (ADR)

- **ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„
- **ì‚°ì¶œë¬¼**: ADR í…œí”Œë¦¿

#### 11.2 API Specification í‘œì¤€
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - OpenAPI/Swagger 3.0
  - API ë¬¸ì„œí™” ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
  - Authentication/Authorization
  - Rate limiting í‘œì¤€

- **ì£¼ìš” ì†ŒìŠ¤**:
  - OpenAPI Specification
  - REST API ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B3-5: API Specification Template

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: API Spec í…œí”Œë¦¿

#### 11.3 Test Case Documentation
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Test case ì‘ì„± í‘œì¤€
  - AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŒ… ì „ëµ
  - Unit, Integration, E2E í…ŒìŠ¤íŠ¸

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Software testing í‘œì¤€
  - ML testing ê°€ì´ë“œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B4-2: Test Case Template

- **ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„
- **ì‚°ì¶œë¬¼**: Test Case í…œí”Œë¦¿

#### 11.4 Technical Documentation í‘œì¤€
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ê¸°ìˆ  ë¬¸ì„œ êµ¬ì¡°
  - Diagrams as Code (Mermaid, PlantUML)
  - Versioning ì „ëµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Docs as Code ë°©ë²•ë¡ 
  - Technical writing ê°€ì´ë“œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B8-2: Technical Documentation Template

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Documentation í‘œì¤€

---

### ğŸš€ 12. Project Management & Delivery

#### 12.1 Agile for AI/ML í”„ë¡œì íŠ¸
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - AI í”„ë¡œì íŠ¸ íŠ¹ì„±ì— ë§ëŠ” Agile ì ìš©
  - Sprint êµ¬ì¡°
  - Experimentation vs Development
  - Backlog management

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Agile for ML
  - Scrum Guide

- **ê´€ë ¨ ë¬¸ì„œ**:
  - F1-1: Project Initiation Process
  - B7-1: Project Plan (Gantt Chart)

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Agile í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ

#### 12.2 Risk & Issue Management
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - í”„ë¡œì íŠ¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬
  - Issue tracking
  - Escalation í”„ë¡œì„¸ìŠ¤

- **ì£¼ìš” ì†ŒìŠ¤**:
  - PMI PMBOK
  - í”„ë¡œì íŠ¸ ê´€ë¦¬ í‘œì¤€

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B7-3: Risk & Issue Log

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Risk Management í”„ë¡œì„¸ìŠ¤

#### 12.3 Change Management
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Kotter 8-step
  - ADKAR model
  - Stakeholder engagement

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Kotter International
  - Prosci ADKAR

- **ê´€ë ¨ ë¬¸ì„œ**:
  - F1-2: Kickoff & Stakeholder Alignment
  - B7-4: Change Request Form

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Change Management ê°€ì´ë“œ

---

### ğŸ“ 13. Training & Capability Building

#### 13.1 AI ì—­ëŸ‰ ëª¨ë¸
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - AI ê´€ë ¨ ì—­í•  ì •ì˜
  - ì—­í• ë³„ í•„ìš” ìŠ¤í‚¬
  - í•™ìŠµ ê²½ë¡œ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - LinkedIn Skills
  - Kaggle Learning Paths
  - ì‚°ì—… í‘œì¤€

- **ê´€ë ¨ ë¬¸ì„œ**:
  - G1-1: AI Roles & Responsibilities
  - G1-2: AI Competency Framework

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: ì—­ëŸ‰ ëª¨ë¸, ìŠ¤í‚¬ ë§¤íŠ¸ë¦­ìŠ¤

#### 13.2 êµìœ¡ í”„ë¡œê·¸ë¨ ì„¤ê³„
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ì„±ì¸ í•™ìŠµ ì´ë¡ 
  - Hands-on lab ì„¤ê³„
  - Assessment ë°©ë²•

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Instructional design
  - Technical training ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - C1-5: AI Capability Building Playbook
  - G2-1: Training Curriculum

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: í”„ë¡œê·¸ë¨ ì„¤ê³„ ê°€ì´ë“œ

---

### ğŸ’¼ 14. Sales & Marketing

#### 14.1 Value Proposition í”„ë ˆì„ì›Œí¬
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Value Proposition Canvas
  - Pain-Solution ë§¤í•‘
  - Differentiation ì „ëµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Strategyzer
  - Sales methodology

- **ê´€ë ¨ ë¬¸ì„œ**:
  - E2-1: Value Proposition Deck
  - C5-1: Sales Conversation Guide

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Value Prop í”„ë ˆì„ì›Œí¬

#### 14.2 Discovery Question ê¸°ë²•
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - SPIN Selling
  - Solution Selling
  - Consultative selling

- **ì£¼ìš” ì†ŒìŠ¤**:
  - SPIN Selling (Neil Rackham)
  - ì»¨ì„¤íŒ… ì˜ì—… ë°©ë²•ë¡ 

- **ê´€ë ¨ ë¬¸ì„œ**:
  - C5-1: Sales Conversation Guide
  - B1-2: Interview Guide Set

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Discovery ì§ˆë¬¸ ê°€ì´ë“œ

#### 14.3 Proposal Writing
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ì œì•ˆì„œ êµ¬ì¡°
  - Storytelling ê¸°ë²•
  - Pricing ì „ëµ
  - Win theme

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Proposal writing ê°€ì´ë“œ
  - ì»¨ì„¤íŒ… ì œì•ˆì„œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - C5-2: Proposal Development Guide
  - E2-5: Proposal Template

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Proposal ê°€ì´ë“œ

#### 14.4 Objection Handling
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ì¼ë°˜ì ì¸ objection ìœ í˜•
  - ëŒ€ì‘ ì „ëµ
  - AI íŠ¹í™” objections (ë¹„ìš©, ë°ì´í„°, ì‹ ë¢°)

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Sales training ìë£Œ
  - AI ì˜ì—… ì¼€ì´ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - C5-1: Sales Conversation Guide
  - E2-4: Common Objections & Responses

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Objection Handling ê°€ì´ë“œ

---

### ğŸ”§ 15. Data & Infrastructure

#### 15.1 Data Architecture Patterns
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Data Lake, Lakehouse, Data Mesh
  - Data pipeline íŒ¨í„´
  - Data governance

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Databricks Lakehouse
  - Data Mesh (Zhamak Dehghani)

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A3-1: Enterprise AI Platform Reference Architecture
  - B4-1: Data Requirements Sheet

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Data Architecture ê°€ì´ë“œ

#### 15.2 Cloud Provider ë¹„êµ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - AWS AI/ML ì„œë¹„ìŠ¤
  - GCP AI Platform
  - Azure OpenAI Service
  - ê°€ê²© ë¹„êµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê° í´ë¼ìš°ë“œ ê³µì‹ ë¬¸ì„œ
  - ë…ë¦½ì  ë¹„êµ ë¦¬í¬íŠ¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-1: Technology Landscape
  - B3-2: Technology Stack Assessment Matrix

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Cloud ë¹„êµí‘œ

#### 15.3 ë³´ì•ˆ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - AI ì‹œìŠ¤í…œ ë³´ì•ˆ ìœ„í˜‘
  - Prompt injection ë°©ì–´
  - Data privacy
  - Access control

- **ì£¼ìš” ì†ŒìŠ¤**:
  - OWASP Top 10 for LLM
  - Cloud security ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D2-1: Technical Best Practices
  - F2-2: Security & Privacy Guidelines

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Security ê°€ì´ë“œ

---

### ğŸ“Š 16. Evaluation & Testing

#### 16.1 LLM Evaluation í”„ë ˆì„ì›Œí¬
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Human evaluation
  - Automated evaluation
  - LLM-as-judge
  - Benchmark datasets

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic Evals
  - OpenAI Evals
  - í•™ìˆ  ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A5-2: AI System Evaluation Framework
  - B4-3: Evaluation Dataset Template

- **ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
- **ì‚°ì¶œë¬¼**: Evaluation í”„ë ˆì„ì›Œí¬

#### 16.2 A/B Testing for AI
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - A/B test ì„¤ê³„
  - í†µê³„ì  ìœ ì˜ì„±
  - Multi-armed bandit

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Experimentation í”Œë«í¼ (Optimizely, LaunchDarkly)
  - A/B testing ë°©ë²•ë¡ 

- **ê´€ë ¨ ë¬¸ì„œ**:
  - A5-2: AI System Evaluation Framework

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: A/B Testing ê°€ì´ë“œ

---

### ğŸŒ 17. Industry-Specific Insights

#### 17.1 ê¸ˆìœµ ì‚°ì—… AI í™œìš©
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ê¸ˆìœµê¶Œ use cases (fraud detection, credit scoring, chatbot)
  - ê·œì œ ìš”êµ¬ì‚¬í•­
  - ì‚¬ë¡€ ì—°êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê¸ˆìœµê¶Œ AI ë¦¬í¬íŠ¸
  - ê·œì œ ê¸°ê´€ ê°€ì´ë“œë¼ì¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D1-2: Financial Services Case Studies

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: ê¸ˆìœµ ì‚°ì—… ì¸ì‚¬ì´íŠ¸

#### 17.2 í†µì‹  ì‚°ì—… AI í™œìš©
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - í†µì‹ ì‚¬ use cases (network optimization, customer service)
  - ê¸°ìˆ ì  íŠ¹ì„±
  - ì‚¬ë¡€ ì—°êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - í†µì‹  ì‚°ì—… ë¦¬í¬íŠ¸
  - ì¼€ì´ìŠ¤ ìŠ¤í„°ë””

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D1-3: Telecom Case Studies

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: í†µì‹  ì‚°ì—… ì¸ì‚¬ì´íŠ¸

#### 17.3 ì œì¡° ì‚°ì—… AI í™œìš©
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - ì œì¡°ì—… use cases (ì˜ˆì§€ë³´ì „, í’ˆì§ˆê´€ë¦¬)
  - IoT í†µí•©
  - ì‚¬ë¡€ ì—°êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ì œì¡° ì‚°ì—… ë¦¬í¬íŠ¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D1-4: Manufacturing Case Studies

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: ì œì¡° ì‚°ì—… ì¸ì‚¬ì´íŠ¸

---

### ğŸ¯ 18. Workshop & Facilitation

#### 18.1 Workshop ì„¤ê³„ ë° ì§„í–‰
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Workshop êµ¬ì¡°
  - Facilitation ê¸°ë²•
  - Engagement ì „ëµ
  - Output ì •ë¦¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Facilitation ê°€ì´ë“œ
  - Design Thinking ë°©ë²•ë¡ 

- **ê´€ë ¨ ë¬¸ì„œ**:
  - F1-2: Kickoff & Stakeholder Alignment
  - C3-2: Use Case Prioritization Guide

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Workshop ê°€ì´ë“œ

#### 18.2 Stakeholder Interview ê¸°ë²•
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Interview protocol
  - ì§ˆë¬¸ ì„¤ê³„
  - Note-taking
  - Insight ë„ì¶œ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - User research ë°©ë²•ë¡ 
  - ì»¨ì„¤íŒ… ì¸í„°ë·° ê¸°ë²•

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B1-2: Interview Guide Set
  - C3-2: Use Case Prioritization Guide

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Interview ê°€ì´ë“œ

---

### ğŸ“š 19. Knowledge Management

#### 19.1 ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - KM í”Œë«í¼ (Confluence, Notion, SharePoint)
  - ë¶„ë¥˜ ì²´ê³„ (taxonomy)
  - ê²€ìƒ‰ ìµœì í™”

- **ì£¼ìš” ì†ŒìŠ¤**:
  - KM ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
  - í”Œë«í¼ ê³µì‹ ë¬¸ì„œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - H1-1: Knowledge Repository Structure
  - H1-2: Documentation Standards

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: KM ì‹œìŠ¤í…œ ê°€ì´ë“œ

#### 19.2 Lessons Learned í”„ë¡œì„¸ìŠ¤
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Retrospective ë°©ë²•
  - í•™ìŠµ í¬ì°© ë° ê³µìœ 
  - Continuous improvement

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Agile retrospectives
  - KM ë°©ë²•ë¡ 

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D3-1: Lessons Learned Template
  - F1-4: Project Closure & Handover

- **ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„
- **ì‚°ì¶œë¬¼**: Lessons Learned í”„ë¡œì„¸ìŠ¤

---

### ğŸ¨ 20. Visualization & Reporting

#### 20.1 Executive Reporting
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Executive summary ì‘ì„±ë²•
  - Data visualization ì›ì¹™
  - Storytelling with data

- **ì£¼ìš” ì†ŒìŠ¤**:
  - McKinsey communication
  - Data visualization ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

- **ê´€ë ¨ ë¬¸ì„œ**:
  - B8-1: Executive Report Template

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Reporting ê°€ì´ë“œ

#### 20.2 Dashboard & Metrics
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - KPI dashboard ì„¤ê³„
  - Real-time vs batch reporting
  - Visualization ë„êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - BI ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
  - Dashboard design

- **ê´€ë ¨ ë¬¸ì„œ**:
  - H2-3: Reporting & Analytics Setup

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Dashboard ê°€ì´ë“œ

---

## LOW PRIORITY - ì¶”ê°€ ë¦¬ì„œì¹˜

### ğŸ“– 21. Advanced Topics

#### 21.1 Constitutional AI & Alignment
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Constitutional AI ê°œë…
  - RLHF (Reinforcement Learning from Human Feedback)
  - AI alignment ì—°êµ¬

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Anthropic ì—°êµ¬ ë…¼ë¬¸
  - AI safety ì—°êµ¬

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-2: Research Paper Library

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Advanced topics ìš”ì•½

#### 21.2 Multimodal AI
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Vision-Language models
  - Document understanding
  - Multimodal RAG

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Claude Vision
  - GPT-4V
  - ì—°êµ¬ ë…¼ë¬¸

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-2: Research Paper Library

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Multimodal ê°€ì´ë“œ

#### 21.3 Fine-tuning & PEFT
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Fine-tuning ì „ëµ
  - LoRA, QLoRA
  - When to fine-tune vs prompt engineering

- **ì£¼ìš” ì†ŒìŠ¤**:
  - HuggingFace PEFT
  - Fine-tuning ì—°êµ¬

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
- **ì‚°ì¶œë¬¼**: Fine-tuning ê°€ì´ë“œ

---

### ğŸŒ 22. Emerging Trends

#### 22.1 AI Trends & Hype Cycle
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Gartner Hype Cycle for AI
  - ìµœì‹  íŠ¸ë Œë“œ (2025)
  - ê¸°ìˆ  ì„±ìˆ™ë„

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Gartner
  - Forrester

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-3: Industry Reports & Trends

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Trends ë¦¬í¬íŠ¸

#### 22.2 Research Paper íë ˆì´ì…˜
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - arXiv ì£¼ìš” ë…¼ë¬¸
  - Conference papers (NeurIPS, ICML)
  - ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±

- **ì£¼ìš” ì†ŒìŠ¤**:
  - arXiv
  - Papers with Code

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-2: Research Paper Library

- **ì˜ˆìƒ ì‹œê°„**: ì§€ì†ì  (ë¶„ê¸° 4-6ì‹œê°„)
- **ì‚°ì¶œë¬¼**: Paper ë¼ì´ë¸ŒëŸ¬ë¦¬

---

### ğŸ› ï¸ 23. Tooling & Automation

#### 23.1 Code Generation & Copilot
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - GitHub Copilot, Cursor
  - AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ í™œìš©
  - Best practices

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê° ë„êµ¬ ë¬¸ì„œ
  - í™œìš© ì‚¬ë¡€

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D2-1: Technical Best Practices

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Tooling ê°€ì´ë“œ

#### 23.2 No-code/Low-code AI
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - LangFlow, FlowiseAI
  - No-code í”Œë«í¼
  - ì ìš© ì‹œë‚˜ë¦¬ì˜¤

- **ì£¼ìš” ì†ŒìŠ¤**:
  - í”Œë«í¼ ë¬¸ì„œ

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-1: Technology Landscape

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: No-code ê°€ì´ë“œ

---

### ğŸŒ 24. Localization & Regional

#### 24.1 í•œêµ­ AI ìƒíƒœê³„
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - í•œêµ­ AI ì •ì±…
  - ì£¼ìš” í”Œë ˆì´ì–´
  - íˆ¬ì ë™í–¥

- **ì£¼ìš” ì†ŒìŠ¤**:
  - ê³¼ê¸°ì •í†µë¶€
  - KISTEP

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-3: Industry Reports & Trends

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: í•œêµ­ ì‹œì¥ ì¸ì‚¬ì´íŠ¸

#### 24.2 ê¸€ë¡œë²Œ AI ê·œì œ ë™í–¥
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - êµ­ê°€ë³„ ê·œì œ
  - Cross-border ì´ìŠˆ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - OECD AI Policy Observatory

- **ê´€ë ¨ ë¬¸ì„œ**:
  - D4-3: Industry Reports & Trends

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: ê·œì œ ë™í–¥ ë¦¬í¬íŠ¸

---

### ğŸ’¡ 25. Innovation & R&D

#### 25.1 AI Innovation í”„ë¡œì„¸ìŠ¤
- **ë¦¬ì„œì¹˜ ë‚´ìš©**:
  - Innovation framework
  - PoC/Pilot ë°©ë²•ë¡ 
  - Fail-fast ì „ëµ

- **ì£¼ìš” ì†ŒìŠ¤**:
  - Innovation ë°©ë²•ë¡ 

- **ê´€ë ¨ ë¬¸ì„œ**:
  - F1-3: Quality Assurance Process

- **ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
- **ì‚°ì¶œë¬¼**: Innovation ê°€ì´ë“œ

---

## ë¦¬ì„œì¹˜ ë°©ë²•ë¡ 

### ğŸ” ë¦¬ì„œì¹˜ ì ‘ê·¼ë²•

#### 1. ì›¹ ê²€ìƒ‰ ì „ëµ
```
âœ“ ê³µì‹ ë¬¸ì„œ ìš°ì„  (Anthropic, OpenAI, Google ë“±)
âœ“ í•™ìˆ  ë…¼ë¬¸ (arXiv, Papers with Code)
âœ“ ì‚°ì—… ë¦¬í¬íŠ¸ (Gartner, Forrester, McKinsey)
âœ“ ê¸°ìˆ  ë¸”ë¡œê·¸ (ê° í”Œë«í¼ ê³µì‹ ë¸”ë¡œê·¸)
âœ“ GitHub repositories (ì¸ê¸° í”„ë¡œì íŠ¸)
âœ“ ì»¤ë®¤ë‹ˆí‹° (Reddit, HackerNews, LinkedIn)
```

#### 2. ì •ë³´ í’ˆì§ˆ ê²€ì¦
```
âœ“ ì¶œì²˜ ì‹ ë¢°ì„± í™•ì¸
âœ“ ìµœì‹ ì„± (2024-2025 ì •ë³´ ìš°ì„ )
âœ“ ë‹¤ìˆ˜ ì†ŒìŠ¤ êµì°¨ ê²€ì¦
âœ“ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„± í‰ê°€
```

#### 3. ë¬¸ì„œí™” ê¸°ì¤€
```
âœ“ ì¶œì²˜ ëª…ì‹œ
âœ“ ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ ê¸°ë¡
âœ“ ì‹¤ë¬´ ì ìš© íŒ í¬í•¨
âœ“ ì˜ˆì‹œ ë° í…œí”Œë¦¿ ì²¨ë¶€
```

---

## ë‹¤ìŒ ë‹¨ê³„

### Phase 1: High Priority ë¦¬ì„œì¹˜ (Week 1-2)
- RAG ì‹œìŠ¤í…œ (20ì‹œê°„)
- Agent Systems (15ì‹œê°„)
- Enterprise Platform (15ì‹œê°„)
- **Total: 50ì‹œê°„**

### Phase 2: Medium Priority ë¦¬ì„œì¹˜ (Week 3-4)
- Templates & Standards (10ì‹œê°„)
- Project Management (10ì‹œê°„)
- Sales & Marketing (10ì‹œê°„)
- **Total: 30ì‹œê°„**

### Phase 3: Low Priority ë¦¬ì„œì¹˜ (Week 5+)
- Advanced Topics (10ì‹œê°„)
- Emerging Trends (10ì‹œê°„)
- Localization (10ì‹œê°„)
- **Total: 30ì‹œê°„**

---

## ì§„í–‰ ìƒí™© ì¶”ì 

| ì¹´í…Œê³ ë¦¬ | í•­ëª© ìˆ˜ | ì™„ë£Œ | ì§„í–‰ì¤‘ | ë¯¸ì‹œì‘ |
|---------|--------|------|--------|--------|
| RAG Systems | 6 | 6 | 0 | 0 |
| Agent Systems | 4 | 0 | 0 | 4 |
| Enterprise Platform | 4 | 0 | 0 | 4 |
| Prompt Engineering | 2 | 0 | 0 | 2 |
| Maturity & Assessment | 2 | 2 | 0 | 0 |
| Risk & Compliance | 4 | 4 | 0 | 0 |
| ROI & Business | 2 | 0 | 0 | 2 |
| LLM Platforms | 2 | 0 | 0 | 2 |
| Monitoring | 2 | 0 | 0 | 2 |
| Operating Model | 2 | 0 | 0 | 2 |
| **High Priority Total** | **35** | **12** | **0** | **23** |

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-23
